name: Scrape Stream URL

on:
  schedule:
    - cron: '*/15 * * * *' # every 10 minutes
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0      # fetch full git history
          ref: main           # checkout main branch explicitly

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'

      - name: Install Dependencies
        run: |
          cd scraper
          npm install

      - name: Run Scraper
        run: |
          cd scraper
          npm start

- name: Commit and Push .json
  env:
    GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  run: |
    git config --global user.name "github-actions"
    git config --global user.email "github-actions@github.com"

    # Set authenticated remote URL for pull and push
    git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}.git

    # Pull latest changes and rebase to avoid conflicts
    git pull --rebase origin main

    # Copy updated stream.json from scraper/
    cp scraper/stream.json stream.json

    # Stage changes
    git add stream.json

    # Conditionally commit if there are any changes
    git diff-index --quiet HEAD || git commit -m "ðŸ‘‰ updated HLS Links"

    # Push only if a commit was made
    if [ "$(git rev-parse HEAD)" != "$(git rev-parse @{u})" ]; then
      git push origin main
    else
      echo "No changes to push."
    fi
